{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm optimization & testing\n",
    "\n",
    "This notebook demonstrates performance testing of four different algorithm implementations which perform the same operation: sorting a list of numbers.\n",
    "\n",
    "## Notebook set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursion depth limit 3000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "import statistics\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "print(f'Recursion depth limit {sys.getrecursionlimit()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algorithm implementations\n",
    "\n",
    "Four functions to sort numbers using: built-in sort, NumPy sort, bubble sort, and merge sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original list: [64, 34, 25, 12, 22, 11, 90, 5, 77, 30]\n",
      "Built-in sort result: [5, 11, 12, 22, 25, 30, 34, 64, 77, 90]\n",
      "NumPy sort result: [5, 11, 12, 22, 25, 30, 34, 64, 77, 90]\n",
      "Bubble sort result: [5, 11, 12, 22, 25, 30, 34, 64, 77, 90]\n",
      "Merge sort result: [5, 11, 12, 22, 25, 30, 34, 64, 77, 90]\n"
     ]
    }
   ],
   "source": [
    "# Built-in sort implementation\n",
    "def builtin_sort(nums: list) -> list:\n",
    "    '''Sorts a list using Python's built-in sorted() function.'''\n",
    "\n",
    "    return sorted(nums)\n",
    "\n",
    "# Numpy implementation\n",
    "def numpy_sort(nums: list) -> list:\n",
    "    '''Sorts a list using NumPy's sort function.'''\n",
    "\n",
    "    nums_array = np.array(nums)\n",
    "\n",
    "    return np.sort(nums_array).tolist()\n",
    "\n",
    "# Bubble sort implementation\n",
    "def bubble_sort(nums: list) -> list:\n",
    "    '''Sorts a list using the bubble sort algorithm.'''\n",
    "\n",
    "    nums = nums.copy()  # Don't modify the original list\n",
    "    n = len(nums)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(0, n - i - 1):\n",
    "            if nums[j] > nums[j + 1]:\n",
    "                nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
    "    \n",
    "    return nums\n",
    "\n",
    "# Merge sort implementation\n",
    "def merge_sort(nums: list) -> list:\n",
    "    '''Sorts a list using the merge sort algorithm.'''\n",
    "\n",
    "    if len(nums) <= 1:\n",
    "        return nums\n",
    "    \n",
    "    mid = len(nums) // 2\n",
    "    left = merge_sort(nums[:mid])\n",
    "    right = merge_sort(nums[mid:])\n",
    "    \n",
    "    return merge(left, right)\n",
    "\n",
    "def merge(left: list, right: list) -> list:\n",
    "    '''Helper function for merge sort to merge two sorted lists.'''\n",
    "\n",
    "    result = []\n",
    "    i = j = 0\n",
    "    \n",
    "    while i < len(left) and j < len(right):\n",
    "        if left[i] <= right[j]:\n",
    "            result.append(left[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            result.append(right[j])\n",
    "            j += 1\n",
    "    \n",
    "    result.extend(left[i:])\n",
    "    result.extend(right[j:])\n",
    "\n",
    "    return result\n",
    "\n",
    "nums = [64, 34, 25, 12, 22, 11, 90, 5, 77, 30]\n",
    "print(f'Original list: {nums}')\n",
    "print(f'Built-in sort result: {builtin_sort(nums)}')\n",
    "print(f'NumPy sort result: {numpy_sort(nums)}')\n",
    "print(f'Bubble sort result: {bubble_sort(nums)}')\n",
    "print(f'Merge sort result: {merge_sort(nums)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All four functions give the same sorted result - but are they equivalent in performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithm implementation testing\n",
    "\n",
    "Let's exclude the bubble sort from large-scale testing. While it's a classic algorithm to understand, it's much less efficient than the other three for large datasets, with O(nÂ²) time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500       # Number of trials to run\n",
    "k = 100000    # Number of random integers to use (reduced for sorting complexity)\n",
    "start = 1000  # Start of range for random test ints\n",
    "end = 1000000 # End of range for random test ints\n",
    "\n",
    "# Functions to test (excluding bubble sort for performance reasons)\n",
    "implementations = ['Built-in sort', 'NumPy sort', 'Merge sort']\n",
    "functions = [builtin_sort, numpy_sort, merge_sort]\n",
    "\n",
    "# Helper function to measure execution time\n",
    "def measure_execution_time(function: Callable, nums: list) -> float:\n",
    "    '''Measures execution time of sorting function. Returns results as float seconds.'''\n",
    "    \n",
    "    start_time = time.time()\n",
    "    function(nums)\n",
    "    return time.time() - start_time\n",
    "\n",
    "# Helper function to measure memory footprint\n",
    "def measure_memory_footprint(function: Callable, nums: list) -> float:\n",
    "    '''Measure memory footprint of sorting function. Returns result as float MB.'''\n",
    "    \n",
    "    mem_usage = memory_usage((function, (nums,)))\n",
    "    return max(mem_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Memory footprint measurement\n",
    "\n",
    "Run memory usage test with n replicates of k numbers each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of empty lists to collect results\n",
    "memory_results = dict(zip(implementations, [[], [], []]))\n",
    "\n",
    "# Collect n memory use measurements with different random lists\n",
    "for trial in range(n):\n",
    "    \n",
    "    # Generate some random integers for this trial\n",
    "    random_list = random.choices(list(range(start, end)), k=k)\n",
    "    \n",
    "    # Measure memory footprint for each implementation\n",
    "    for implementation, function in zip(implementations, functions):\n",
    "        max_memory = measure_memory_footprint(function, random_list)\n",
    "        memory_results[implementation].append(max_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Execution time measurement\n",
    "\n",
    "Run execution time test with n replicates of k numbers each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of empty lists to collect results\n",
    "time_results = dict(zip(implementations, [[], [], []]))\n",
    "\n",
    "# Collect n execution time measurements for each function with different random lists\n",
    "for trial in range(n):\n",
    "    \n",
    "    # Generate some random integers for this trial\n",
    "    random_list = random.choices(list(range(start, end)), k=k)\n",
    "    \n",
    "    # Measure execution time for each function on the random integer list\n",
    "    for implementation, function in zip(implementations, functions):\n",
    "        execution_time = measure_execution_time(function, random_list)\n",
    "        time_results[implementation].append(execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Results\n",
    "\n",
    "Use a histogram to plot the results for each trial of each function implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate common memory and time bins across each function implementation\n",
    "_, memory_bins = np.histogram(sum(memory_results.values(), []), bins=20)\n",
    "_, time_bins = np.histogram(sum(time_results.values(), []), bins=20)\n",
    "\n",
    "# Set-up a 1x2 plot for memory and time results\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "fig.suptitle(f'Sorting algorithm performance results\\n(n={n}, k={k})')\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Draw the memory plot\n",
    "for implementation, data in memory_results.items():\n",
    "    axs[0].hist(data, bins=memory_bins, alpha=0.7, label=implementation)\n",
    "\n",
    "axs[0].set_title('Memory footprint')\n",
    "axs[0].set_xlabel('Memory footprint (MB)')\n",
    "axs[0].set_ylabel('Trials')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].legend(loc='best')\n",
    "\n",
    "# Draw the time plot\n",
    "for implementation, data in time_results.items():\n",
    "    axs[1].hist(data, bins=time_bins, alpha=0.7, label=implementation)\n",
    "\n",
    "axs[1].set_title('Execution time')\n",
    "axs[1].set_xlabel('Execution time (sec.)')\n",
    "axs[1].set_ylabel('Trials')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in sort and merge sort show similar memory footprints, while NumPy sort tends to use more memory due to array conversion overhead. In terms of execution time, Python's built-in sort (Timsort) is typically the fastest, being highly optimized for real-world data patterns. Merge sort shows consistent O(n log n) performance, while NumPy sort may have additional overhead from list-to-array conversion.\n",
    "\n",
    "## 4. Time complexity measurement\n",
    "\n",
    "### 4.1. Execution time as a function of input size\n",
    "\n",
    "Time the execution of n trials on k integers, this time using increasing input list sizes to observe scaling behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of test input lengths using powers of 2 (smaller range for sorting complexity)\n",
    "input_lengths = [2**j for j in range(8, 15)]\n",
    "\n",
    "# Dictionaries of empty lists to collect means and standard deviations\n",
    "# of time results for each function implementation\n",
    "means = dict(zip(implementations, [[], [], []]))\n",
    "stdevs = dict(zip(implementations, [[], [], []]))\n",
    "\n",
    "# Loop over the input number list lengths\n",
    "for input_length in input_lengths:\n",
    "    \n",
    "    # Dictionary of empty lists to collect times for this input length\n",
    "    time_results = dict(zip(implementations, [[], [], []]))\n",
    "    \n",
    "    # Collect n speed measurements with different random lists\n",
    "    for trial in range(n):\n",
    "        \n",
    "        # Generate some random integers for this trial\n",
    "        random_list = random.choices(list(range(start, end)), k=input_length)\n",
    "        \n",
    "        # Measure execution time for each function on the random integer list\n",
    "        for implementation, function in zip(implementations, functions):\n",
    "            execution_time = measure_execution_time(function, random_list)\n",
    "            time_results[implementation].append(execution_time)\n",
    "    \n",
    "    # Collect mean and standard deviation of execution times for each function\n",
    "    # for this input length\n",
    "    for implementation in implementations:\n",
    "        means[implementation].append(statistics.mean(time_results[implementation]))\n",
    "        stdevs[implementation].append(statistics.stdev(time_results[implementation]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Results\n",
    "\n",
    "Plot the results using a line for the mean and a shaded region for mean +/- standard deviation of each function implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Execution time as a function of input size')\n",
    "\n",
    "# Loop to plot each function implementation\n",
    "for implementation in implementations:\n",
    "    \n",
    "    # Plot means\n",
    "    plt.plot(input_lengths, means[implementation], marker='o', label=implementation)\n",
    "    \n",
    "    # Plot shaded region for +/- one standard deviation from the mean\n",
    "    plt.fill_between(\n",
    "        input_lengths,\n",
    "        np.array(means[implementation]) + np.array(stdevs[implementation]),\n",
    "        np.array(means[implementation]) - np.array(stdevs[implementation]),\n",
    "        alpha=0.3\n",
    "    )\n",
    "\n",
    "plt.xlabel('Input size')\n",
    "plt.ylabel('Time (sec.)')\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's built-in sort (Timsort) generally outperforms the other implementations due to its sophisticated optimizations for real-world data patterns. All three sorting algorithms demonstrate approximately O(n log n) time complexity, which is optimal for comparison-based sorting algorithms. The log-log plot shows the characteristic scaling behavior where doubling the input size increases execution time by slightly more than a factor of 2 (due to the logarithmic component). \n",
    "\n",
    "For practical applications, Python's built-in sort is usually the best choice unless specific requirements (like guaranteed worst-case performance) dictate otherwise. Merge sort provides consistent O(n log n) performance regardless of input characteristics, while NumPy sort can be beneficial when working with numerical data that's already in array format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
